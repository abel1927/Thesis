\chapter{Estado del Arte}\label{chapter:state-of-the-art}


    Los sistemas de GLN normalmente reciben los datos de forma estructurada, pero esta estructura puede variar de un sistema a otro.
La naturaleza de los datos es diferente con lo cual sus representaciones pueden ser desde registros de bases de datos, bases de conocimiento, 
grafos de conocimiento, o estructuras intermedias que utilizan representaciones del tipo clave-valor como pudiera ser el formato JSON, entre otras. 
Por ejemplo, en algunos obtienen los datos en forma de series temporales \brackcite{Yu2006ChoosingTC}, mientras que otros los trabajan a 
partir de una base de datos de registros financieros \brackcite{kukich1983design}.

En cuanto a la arquitectura, el diseño de sistemas de GLN es un campo abierto donde no existe un amplio consenso. Hay una diversidad de propuestas e implementaciones 
que varían en dependencia del desarrollador y del problema para el cual se crea el sistema de GLN. En este sentido, es difícil identificar elementos comunes y proporcionar una abstracción 
completa que sea aplicable a la mayoría de éstos sistemas \brackcite{ramos2016role}.


 Sin embargo, la arquitectura propuesta por Riter y Dale en \brackcite{Reiter1997BuildingAN} se ha tomado como el estandar de facto 
dentro de este campo, lo que no implica que muchos sistemas no plantearan estructuras diferentes \brackcite{Perera2017RecentAI}. 
Esta arquitectura de flujo (\emph{pipeline} en inglés), o modular, establece que los sistemas de GLN pueden dividirse en módulos 
que encapsulen distintas tareas dentro del proceso de generación del texto.

    

    \begin{figure}[!]
        \begin{center}
            \includegraphics[width=\textwidth]{Graphics/arquitecturaPipeline_Capa 1.png}
        \end{center}
        \caption{Arquitectura modular \brackcite{Reiter1997BuildingAN}.}
        \label{fig_arq_Pipeline}
    \end{figure}


\section{Tareas principales de los sistemas de Generación de Lenguaje Natural}

    Hasta hoy, considerado como el punto de referencia y texto más completo en el campo de GLN \brackcite{Gatt2018SurveyOT}, el libro de Ehud Riter y
Robert Dale: Building Natural Language Generation Systems \brackcite{reiter_dale_2000}, sienta las bases y define las que se han asumido como tareas principales 
de un sistema de GLN:

\begin{itemize}
    \item Determinación del contenido: decidir qué información es relevante.
    \item Estructuración del texto: determinar en qué orden se presentará la información.
    \item Agregación: decidir qué información se presenta en cada oración.
    \item Lexicalización: encontrar las palabras y frases adecuadas para expresar información.
    \item Generación de expresiones de referencia: selección de las palabras y frases para identificar entidades del dominio.
    \item Realización lingüística: conformación del texto con oraciones bien formadas.
\end{itemize}


Estas tareas naturalmente se pueden dividir entre las que envuelven el proceso de elegir qué decir y de qué forma (planificación del contenido) 
a partir de los datos, y las que tienen un carácter más orientado al proceso lingüístico de elegir los términos adecuados para la expresión 
en sí (realización) \brackcite{Gatt2018SurveyOT}. Cada una de estas tareas, aunque no presentes en su conjunto en todos los sistemas, responden a distintos 
objetivos dentro de los mismos y existen distintas técnicas para cada una de ellas en la literatura.
    
\subsection{Determinación del contenido}\label{subsection:selecciondelcontenido}

    Cada sistema de GLN tiene un objetivo comunicativo, lo cual hace necesario determinar qué información del dominio es relevante y debe 
estar representada en el texto final \brackcite{reiter_dale_2000}. Los sistemas pueden presentar una especificación de los datos de la entrada 
o seleccionar un subconjunto de los mismos \brackcite{reiter_dale_2000}.

    El reconocimiento de patrones es una de las t\'ecnicas utilizadas con este fin.  SumTime-Turbine \brackcite{Yu2006ChoosingTC} es un ejemplo de sistema funcional para crear
 informes sobre un mecanismo de turbinas de gas. En un contexto donde la cantidad de datos es muy grande y en su mayoría irrelevante, 
 los autores con ayuda de los expertos del dominio crean un modelo que permite reconocer patrones en los datos así como luego, utilizando una base de datos de patrones 
antiguos determinar los patrones relevantes a ser expresados en el informe. 

    Existen muchos sistemas de GLN que utilizan modelos basados en reglas como \'unica metodolog\'ia para la selecci\'on de contenido \brackcite{reiter_dale_2000,Perera2017RecentAI}. Bouayad-Agha, Casamayor y 
Wanner \brackcite{BouayadAgha2011ContentSF} presentaron el dise\~no te\'orico de un sistema para generar resúmenes de partidos de 
fútbol de la Liga Espa\~nola. Para la conformaci\'on del mismo describieron la construcci\'on de una gran base de conocimientos del dominio as\'i como 
un estricto sistema de reglas para la selecci\'on de contenido. Es relevante este enfoque, ya que con un conocimiento del dominio a tratar y de la intenci\'on comunicativa del texto a producir 
es posible implementar reglas que den lugar a la selección del contenido relevante \brackcite{Reiter1997BuildingAN,reiter_dale_2000}. 

    Como el proceso de creaci\'on de reglas puede ser tedioso y es dependiente del dominio \brackcite{Reiter1997BuildingAN}, aparecieron iniciativas para la automatizaci\'on de esta tarea. Un enfoque 
basado en t\'ecnicas de aprendizaje autom\'atico es el presentado por Dubou\'e y McKeown \brackcite{Dubou2003StatisticalAO}. En este trabajo plantearon un modelo de aprendizaje supervisado que a trav\'es de
un corpus de resultados deseados (texto escrito por humanos), aparejados con los tipos lingüísticos de la entrada (distintos tipos de datos que recibe el sistema), determina un conjunto de constantes. Estas constantes 
expresan si determinado dato de entrada debe aparecer o no reflejado en la salida y bajo qué condiciones. Este sistema se utilizó para la generación de descripciones biográficas cortas que resumen hechos 
importantes sobre personajes famosos.

\subsection{Estructuración del texto}\label{subsection:estructuracion}

    La estructuración del texto o planificación del discurso es el proceso donde se da orden y estructura al conjunto de mensajes a expresar en el texto producido. En un texto la información se presenta en un orden particular 
y, por lo general, hay una estructura subyacente a la presentación. La complejidad de la estructura de los textos puede variar de un sistema a otro. Una buena estructuración puede hacer que un texto sea mucho más fácil 
de leer \brackcite{Reiter1997BuildingAN}.

    Los primeros enfoques para la estructuración de documentos se basaron en reglas estructuradas hechas a mano dependientes del dominio \brackcite{Gatt2018SurveyOT}. A este enfoque se le conoce como el enfoque basado en esquemas, nombre que 
se deriv\'o del trabajo de Kathleen R. McKeown \brackcite{mckeown1985discourse} cuando acu\~n\'o el t\'ermino \textit{"schematta"}. En la construcci\'on de su sistema TEXT \brackcite{mckeown1985discourse}, McKeown, luego del análisis de muchos 
ejemplos del dominio, concluyó que dado un objetivo comunicativo, la información tiende a transmitirse en el mismo orden. En base a esto defini\'o estructuras (esquemas) que determinan posibles combinaciones de atributos, formando patrones 
y plantillas. De esta forma, el sistema, dada una intenci\'on comunicativa, puede seleccionar un esquema que defina la forma de transmitir la información. La mayor\'ia de los sistemas que siguen este enfoque utilizan 
las Matrices de Valores de Atributos (AVMs por sus siglas en inglés, \emph{Attribute Value Matrics}) \brackcite{Perera2017RecentAI}.

    Las estructuras ret\'oricas son otro de los mecanismos que se utilizan para la planificación. Estas se derivan del trabajo de Mann y Thompson quienes introdujeron la Teor\'ia de la Estructura Ret\'orica(RST por
sus siglas en inglés, \emph{Rhetorical Structure Theory}) \brackcite{mann1988rhetorical}. Las estructuras ret\'oricas constituyen un m\'etodo lingüístico para la descripci\'on de texto caracterizando las estructuras primarias del mismo y estableciendo 
relaciones funcionales entre sus distintas partes. La RST tiene como base los conceptos de n\'ucleo y sat\'elite que definen las partes del texto entre las que se establece una relaci\'on. Los distintos sistemas que utilizan las estructuras ret\'oricas 
para la estructuraci\'on del texto definen qué tipo de relaciones establecen. Ejemplos de relaciones lingüísticas planteadas por Mann y Thompson en su trabajo son: motivaci\'on, causa, condici\'on, circunstancia, entre otros \brackcite{mann1988rhetorical}. 

\subsection{Agregación}\label{subsection:agregacion}

    En un texto, cada parte de información no tiene que estar presente en oraciones independientes. Hay escenarios donde es 
deseable que distintos mensajes sean transmitidos en una misma oraci\'on. La agregaci\'on puede permitir crear textos de mayor 
calidad o eliminar repeticiones innecesarias que vayan en contra de la fluidez del mismo \brackcite{Gatt2018SurveyOT}). Reape y Mellish \brackcite{reape1999just}
realizaron un estudio sobre la tarea de agregación dentro de los sistemas de generación de texto, distinguiendo entre la agregación a nivel semántico (más dependiente del dominio)
y a nivel sintáctico. Muchos de los primeros trabajos sobre agregación fueron dependientes del dominio, centrados en la aplicación de reglas 
(por ejemplo, "si un jugador marca dos goles consecutivos, expr\'esalo en la misma frase"). 

    Un ejemplo de agregaci\'on, en el dominio del f\'utbol, describiendo el hecho de dos anotaciones consecutivas de un jugador, pudiera ser:

\begin{itemize}
    \item (1) Ronaldo anot\'o para el Real Madrid en el minuto 2. Ronaldo anot\'o para el Real Madrid en el minuto 8.
    \item (2) Ronaldo anot\'o dos veces para el Real Madrid antes del minuto 8.
\end{itemize}

    En el segundo caso, se evita la repetici\'on y la información se presenta de forma m\'as fluida y natural al lector.
    
Los primeros trabajos de este tipo se basaron generalmente en la aplicación de reglas hechas a mano (ejemplo \brackcite{Shaw1998ClauseAU}). Con el tiempo aparecieron propuestas que 
utilizan enfoques de aprendizaje autom\'atico. SPoT \brackcite{walker2001spot} constituyó uno de los primeros sistemas entrenados que incluye la tarea de agregación. 
Los autores plantearon una metodolog\'ia basada en la producci\'on de varios textos para una misma entidad informativa utilizando diferentes cl\'ausulas de agregación asociadas al dominio. Despu\'es utilizaron un modelo 
entrenado para dar un valor a cada una de las salidas estableciendo un ranking a partir del cual hacer la selección. Mientras, Barzilay y Lapata \brackcite{Barzilay2006AggregationVS}
plantearon el problema en términos de optimización global. Realizan una clasificación inicial sobre pares de entradas de la base de datos que determina 
si deben agregarse o no en función de su similitud por pares. Posteriormente, seleccionan un conjunto globalmente óptimo de entradas relacionadas en función
de un grupo de restricciones.

    Con la agregación sintáctica podría decirse que es más factible definir reglas independientes del dominio para eliminar la 
redundancia \brackcite{Gatt2018SurveyOT}. Esto podría lograrse identificando las frases verbales paralelas en las dos oraciones conjuntas y eliminando el sujeto y el verbo en la segunda. 
Por ejemplo, convertir (3) en (4):

\begin{itemize}
    \item (3) Ronaldo marcó en el minuto 2 y marcó de nuevo en el minuto 8.
    \item (4) Ronaldo marcó en el minuto 2 y de nuevo en el 8.
\end{itemize}
    


\subsection{Lexicalización}\label{subsection:lexicalizacion}

    La lexicalización es un proceso muy importante dentro de un sistema de GLN. Es el proceso durante el cual se 
seleccionan la palabra o palabras que expresan un concepto o relaci\'on \brackcite{Reiter1997BuildingAN}. Una de las 
complicaciones del proceso de lexicalización est\'a dada porque una misma relación puede ser expresada de 
distintas formas. Por ejemplo, el evento de la anotación de un gol en un partido de fútbol puede ser expresado como:
¨marcar un gol¨, ¨poner el balón en la red¨, ¨conseguir una anotación¨. La complejidad de este proceso depende en gran 
medida del número de alternativas que el sistema pueda o quiera contemplar. Las restricciones contextuales también juegan 
un papel importante a la hora de expresar un mensaje. Por ejemplo, la expresión ¨marcó un gol¨ es desafortunada si el evento 
descrito es un gol en propia puerta \brackcite{Gatt2018SurveyOT}.

    El proceso de lexicalización puede seguir dos vertientes principales. Una ser\'ia la realizaci\'on de la  
lexicalización de la forma m\'as simple posible, lo cual se lleva a cabo generalmente utilizando t\'ecnicas para el llenado de 
plantillas lexicalizadas. De otra forma se puede realizar este proceso en mayor profundidad utilizando t\'ecnicas m\'as complejas  
que permitan, por ejemplo: la eliminaci\'on de palabras innecesarias, la selección de vocablos que maximicen la efectividad del objetivo 
comunicativo del texto o la uni\'on de t\'erminos que se aparejan frecuentemente en el dominio \brackcite{Perera2017RecentAI}.

    Los enfoques basados en reglas son de los m\'as utilizados, pudiendo variar en complejidad entre un sistema y otro. \textit{EasyText}\brackcite{danlos2011easytext} 
es un ejemplo de sistema que utiliza reglas para la lexicalización, pero que da un paso m\'as all\'a pues consume de una base de datos 
l\'exica creada, principalmente, por lingüistas. Esta alternativa permite una lexicalización m\'as avanzada, pero a su vez es altamente 
costosa en recursos.

    La utilizaci\'on de ontolog\'ias tambi\'en est\'a presente en este proceso de los sistemas de GLN. El uso de ontologías permite 
al sistema ganar en adaptabilidad, ya que encontrar una ontología para un dominio determinado es más sencillo que encontrar un corpus para 
el mismo. Asimismo, ofrecen una mayor cobertura de las representaciones semánticas que los corpus \brackcite{Perera2017RecentAI}. Cimiano \brackcite{cimiano2013exploiting} introdujo 
un modelo que utiliza este enfoque presentado en el dominio de las recetas de cocina.


\subsection{Expresiones de referencia}\label{subsection:expreferencia}

    Robert Dale y Ehud Rither describieron la generación de expresiones de referencia dentro de un sistema de GLN como la tarea de 
identificar la expresión a utilizar, comprensible de cara al usuario, para identificar a una instancia del dominio \brackcite{reiter_dale_2000,Gatt2018SurveyOT}. 
Los primeros m\'etodos para la selección de referencias fueron los algoritmos generativos que en común presentan la necesidad de tener conocimiento 
contextual y de propiedades de las entidades \brackcite{Gatt2018SurveyOT}. De este orden es el algoritmo incremental cuya base se plante\'o en \brackcite{dale1995computational}. 
El algoritmo, conociendo la entidad a referenciar (objetivo), el resto de entidades (llamadas distractores) y el grupo de propiedades que definen entidades en el dominio,
busca determinar un conjunto de propiedades \'unicas que definan al objetivo y lo diferencien del resto.

    Muchos de los trabajos que versan sobre este tema hacen énfasis en un tipo determinado de referencia \brackcite{ferreira2018neuralreg}. La selección 
puede ser de un pronombre (\'el/ella), una descripci\'on (Sim\'on, el jugador cubano) o en la generación de nombres propios (Frederich Cepeda/Cepeda). 
Rither y Dale \brackcite{reiter_dale_2000} plantean una diferencia entre una referencia temprana (primera vez que se menciona una 
entidad en el texto) y una tard\'ia (cuando se refiera a una entidad mencionada anteriormente). Plantearon el uso de los nombres propios a la hora 
de introducir una entidad, para luego, a través de claúsulas, seleccionar un pronombre apropiado, ejemplo:

\begin{verbatim}
    si el referente fue mencionado en la oración anterior;
    entonces utiliza un pronombre
\end{verbatim}

Es necesario también considerar los escenarios donde la generaci\'on de expresiones de referencia pudiera llevar a ambigüedades:

\begin{itemize}
    \item Benzema anotó dos para el Real Madrid mientras Luka Modric brindó dos asistencias. Él fue elegido el jugador del partido... 
\end{itemize}

    Siddharthan y col. \brackcite{siddharthan2011information} realizaron un estudio emp\'irico del comportamiento de las referencias hacia personas basadas en 
su nombre propio en el contexto de los art\'iculos de noticias. Para ello utilizaron un corpus de noticias en inglés de diferentes agencias de prensa y 
cuantificaron las diferentes formas de referencia seg\'un el momento referencial de la instancia (temprana o tard\'ia). Como resultado de este trabajo 
arrojaron que el nombre completo de la entidad suele utilizarse como primera referencia en pr\'acticamente totalidad de los casos, mientras que en su mayor\'ia
el apellido se utiliza cuando se trata de una referencia tard\'ia. 

   %Entre las propuestas recientes para la generaci\'on de entidades referenciales encontramos la presentada en \brackcite{ferreira2018neuralreg}. Los autores presentan 
%\textit{NeuralREG}, un modelo de aprendizaje profundo implementado como multi-encoder, attention-decoder con biderectional LSTM(Long-Short Term Memory). Para el 
%entrenamiento modelo utilizaron una versi\'on deslexicalizada del corpus \textit{WebNLG}. Cada entidad presente en los datos fue mapeada
% con diferentes etiquetas de forma tal que 

\subsection{Realización lingüística}\label{subsection:realizcion}

    El proceso de realizaci\'on lingüística es el que da lugar a la formaci\'on final del texto expresado en oraciones con una 
estructura gramatical correcta y coherente con el mensaje a transmitir. Esta tarea implica ordenar los constituyentes de una oración, 
así como generar las formas morfológicas correctas (incluidas las conjugaciones y la concordancia de los verbos). A menudo, los 
realizadores también necesitan insertar palabras funcionales (como verbos auxiliares y preposiciones) y signos de puntuación \brackcite{Gatt2018SurveyOT}.
   
    Una de las t\'ecnicas m\'as utilizadas es la que incluye el uso de plantillas predefinidas para expresar mensajes \brackcite{Gatt2018SurveyOT}. Las 
plantillas, aunque requieren una carga intensiva de trabajo para lograr mayor variabilidad en el texto a producir, permiten un control total sobre 
la calidad y la correctitud del texto a elaborar. Un ejemplo de plantilla:

\begin{verbatim}
    $equipo_1 venció $pts_equipo_1 a $pts_equipo_2 a $equipo_2
\end{verbatim}

    Dicha plantilla, que representa el resultado de un enfrentamiento entre dos equipos se completa con la información extraída de los datos y a la hora de 
la realización el resultado pudiera ser el siguiente:

\begin{verbatim}
    Industriales venció 10 a 1 a Granma
\end{verbatim}

\section{Propuestas para la generación de texto basadas en redes neuronales }
    Al igual que en otras áreas del procesamiento de lenguaje natural, el dominio de la GLN se ha visto 
impactado por el auge de las soluciones basadas en redes neuronales \brackcite{Gatt2018SurveyOT,sharma2022innovations}. 
Mientras los sistemas tradicionales de D2T siguen una estructura modular con etapas bien definidas (estructuración, realización, etc), 
los modelos neuronales variaron el camino hacia estructuras \emph{end-to-end} (de extremo a extremo, en español), unificando 
en muchos casos, varias tareas en un solo paso de entrenamiento.

    Los trabajos que siguieron este enfoque \brackcite{lebret-etal-2016-neural,mei2016talk,wiseman-etal-2017-challenges} plantearon modelos \emph{Seq2Seq} (de secuencia a secuencia, en español) que adoptan la 
influyente estructura de codificador-decodificador \brackcite{sutskever2014sequence}. Utilizan una red neuronal recurrente (RNN, \emph{Recurrent Neural Network}, en inglés) 
para codificar la entrada de un vector de representación el cual sirve a su vez como entrada auxiliar de otra RNN que hace de decodificador y produce el texto, y no tienen módulos 
específicos para mejorar la calidad del resultado más allá de los mecanismos gen\'ericos de atención y copia \brackcite{bahdanau2014neural,gu2016incorporating}. La popularidad de los modelos 
\emph{end-to-end} se vio impulsada y a la vez creó la necesidad de contar con corpus de datos paralelos que permitieran evaluar la calidad de las propuestas. Estos conjuntos de datos tenían que 
tener la suficiente cantidad de instancias para poder entrenar modelos de estas características. RotoWire \brackcite{wiseman-etal-2017-challenges} es un punto de referencia ampliamente utilizado, que se construyó con cerca de 
cinco mil pares de datos estadísticos de partidos de baloncesto y su correspondiente resumen descriptivo escrito por profesionales. MLB \brackcite{puduppully2019data} es otro corpus de reciente creación, cuenta con aproximadamente 
25 mil instancias de estadísticas aparejadas con descripciones, en este caso, en el dominio del beisbol. Otros conjuntos de datos hechos a mano como E2E \brackcite{novikova2017e2e} se han construido para analizar tareas espec\'ificas 
como la capacidad de realización lingüística.

        \begin{figure}[!]
            \begin{center}
                \includegraphics[width=\textwidth]{Graphics/rotowire_instancia.png}
            \end{center}
            \caption{Instancia de RotoWire \brackcite{wiseman-etal-2017-challenges}.}
            \label{fig_RotoWire}
        \end{figure}

 Weiseman y col. \brackcite{wiseman-etal-2017-challenges} mostraron la capacidad de estos modelos de producir un texto dotado de mayor 
fluidez en comparación con propuestas tradicionales. A su vez, además de ser propensos a la alucinación (es decir, generan texto que no es compatible con la entrada), 
mostraron  deficiencias a la hora de seleccionar el contenido y/o estructurar el documento (por ejemplo, en el marco de una descripción biográfica, la omisión de la fecha de nacimiento es un relevante, 
mientras que de aparecer no es apropiado que lo haga en la última oración del escrito). Para mejorar esta situación, Puduppully y col. \brackcite{puduppully2019dataselandplan}  
presentaron una arquitectura que incorpora selección y planificación de contenido sin sacrificar el entrenamiento \emph{end-to-end}. Descompusieron la tarea de generación en dos etapas. Dado el corpus de 
registros de datos (junto con las descripciones), primero generaron un plan de contenido destacando qué información debía mencionarse y en qué orden para luego generar el documento teniendo en 
cuenta dicho plan. Un enfoque similar lo plantearon Chen y col. \brackcite{chen2021neural}, mientras que Moryossef y col. \brackcite{moryossef2019step} desacoplaron por completo ambas fases, dejando solo el modelo 
neuronal para la realización del texto una vez desarrollada la estructura informativa.

        \begin{figure}[!]
            \begin{center}
                \includegraphics[scale=0.4]{Graphics/lapata_arquitectura.png}
            \end{center}
            \caption{Arquitectura del modelo presentado por Puduppully y col. \brackcite{puduppully2019dataselandplan}.}
            \label{fig_lapata_arquitectura}
        \end{figure}


    La utilización de modelos preentrenados en tareas de generación de texto-a-texto para producir texto a partir de datos en base al reentrenamiento 
fue de los enfoques que se exploraron recientemente. Kale y Rastogi \brackcite{kale2020text} utilizaron el modelo T5 (\emph{“Text-to-Text Transfer Transformer”}, su nombre en inglés) \brackcite{raffel2020exploring}
preentrenado para tareas de generación de resúmenes, traducción entre idiomas, clasificación de texto, entre otras. Sus resultados fueron alentadores sobre todo desde el punto de vista de 
la generalización. Este modelo no solo tuvo una buena actuación en cuanto a la calidad del texto generado, sino que también mostró buena adaptación a dominios distintos a los 
del reentrenamiento, lo cual constituyó una diferencia respecto a los modelos neuronales tratados anteriormente.


    Como quedó patente en varios trabajos \brackcite{wiseman-etal-2017-challenges,ferreira2019neural,duvsek2020evaluating,sharma2022innovations} los sistemas basados en redes neuronales
son capaces de producir texto que supera en fluidez y en evaluaciones humanas, como la naturalidad, a los sistemas tradicionales. Sin embargo, estos modelos siguen lidiando con su principal
problema que es la presencia de alucinaciones en las salidas. Esta deficiencia es objeto de interés de los investigadores en este campo \brackcite{ji2022survey}. Por esta razón, Robert Dale, 
en su \textit{Natural language generation: The commercial state of the art in 2020} \brackcite{dale2020natural} planteó que estas soluciones, aunque prometedoras, se 
encuentran en fase principalmente académica y que en la industria, entorno donde la fidelidad de los datos es crucial, su adopción general no ha llegado aún.   


\section{Sistemas para la generación de texto a partir de datos}

    Al referirse al campo de GLN, se puede afirmar que el mismo es ya un campo investigativo consolidado dada la cantidad 
de sistemas que han sido implementados y la variedad de los dominios de su aplicación práctica. FOG (\emph{Forecasting Generator}, en inglés) \brackcite{goldberg1994using} es 
de los primeros sistemas funcionales para la generación de texto a partir de datos. Este, al igual que SumTime \brackcite{reiter2005choosing}, genera breves pronósticos del tiempo
a partir de los valores de variables meteorológicas. 

    En la escena industrial, propiciado por el desarrollo constante de herramientas para el análisis y captura de datos,
hubo empresas que detectaron en la generación de texto un nicho de mercado no cubierto y prometedor \brackcite{dale2020natural}. Compañías como \textit{Ax Semantic\footnote[1]{https://en.ax-semantics.com/}} y 
\textit{Narrativa\footnote[2]{https://www.narrativa.com/}} ofrecen soluciones para automatizar la descripción de productos para el comercio electrónico. 
\textit{Automated Insights} creó su plataforma para la generación de lenguaje natural, \textit{Wordsmith}. Este software da la posibilidad al usuario de crear un conjunto 
de plantillas basadas en reglas que describen los datos que se desea tratar. A partir de las mismas, y en dependencia de su sofisticación los textos generados pueden llegar a ser 
indistinguibles de los textos redactados por un humano. Precisamente en colaboración con \textit{Automated Insights}, la gran corporación de prensa \textit{Associated Press (AP)} generó
las vistas previas de los partidos de una temporada regular de baloncesto, liberando a los periodistas de este trabajo. A su vez, \textit{Yahoo!} utiliza esta tecnología para crear informes 
de jugadores y resúmenes de partidos de fútbol del juego \textit{Fantasy Football} que es de gran interés para sus usuarios. Otro caso de uso dentro de la automatización de contenido en la prensa lo encontramos en
\textit{PostData\footnote[3]{http://www.postdata.club/index.html}}, un sitio de periodismo 
de datos cubano, donde utilizan un modelo propio, \textit{ArmandBot} \brackcite{balboa2020}, para generar reportes sobre las actuaciones de los peloteros cubanos en grandes ligas.

    En la literatura hay propuestos varios modelos de sistemas para la GLN en el ámbito del deporte. Por ejemplo, Kanerva y col. \brackcite{kanerva2019template} apoyados en la construcción de un corpus de 2000 encuentros de hockey sobre hielo, 
proponen un modelo de secuencia a secuencia, para generar narrativas sobre esta práctica deportiva. Hasan \brackcite{hasan2011automatic} propuso un sistema basado en plantillas que sigue la arquitectura tradicional basada en módulos para 
generar texto en inglés y bengalí\footnote[5]{El bengalí es el idioma nacional y el idioma oficial de la República Popular de Bangladesh} para generar resúmenes de juegos de críquet a partir de datos estructurados obtenidos de la web. 
Siguiendo el mismo enfoque, se presentó otro sistema basado en plantillas para el críquet, en este caso al estilo propio de Sri Lanka \brackcite{gu2016incorporating}.
 
En el caso del fútbol, una de las principales propuestas fue GoalGetter \brackcite{theune2001data}, un sistema de datos a voz en idioma neerlandés, que consta de dos módulos, uno para transformar los datos en texto y 
otro para luego llevar el texto a sonido. GoalGetter tomó los datos de una página de Telexto que contenía la información de uno o más partidos de fútbol. Una característica de este sistema es que propuso una arquitectura diferente al 
estándar modular de otros sistemas. En este caso, utilizó un solo módulo para la generación de texto que consumía una base de conocimiento con los nombres de los jugadores y equipos junto a un sistema de plantillas sintácticas.
Basado en este trabajo se propuso GameRecapper \brackcite{aires2016automatic}, un sistema capaz de generar resúmenes de partidos de fútbol de la liga portuguesa en idioma portugués. Este sistema obtenía los datos de \textit{www.zerozero.pt},
una página web que contenía la información de los partidos de cada jornada. Al módulo de generación agregaron a su vez una base de conocimiento y un conjunto de funciones léxico semánticas para mejorar la calidad del texto. De este trabajo resaltó el hecho 
de que hicieron una caracterización más amplia del evento principal del fútbol, el gol, en su sistema de plantillas. Para cada escenario distinto propusieron la creación de plantillas oracionales específicas (primer gol del partido, último gol, gol que empata, entre otros).

PASS \brackcite{van2017pass} es una propuesta también basada en GoalGetter que busca diferenciar el texto producido en base a la audiencia del mismo. Para ello establecen un sistema de plantillas que abarca distintos posibles escenarios de resultado de un partido: victoria o derrota 
del equipo local, victoria o derrota del equipo visitante o empate. La elección de cuál plantilla utilizar va en dependencia de a qué afición irá dirigido el texto.  

    La gran mayoría de estos sistemas cuentan con un dominio específico de aplicación, así como cuentan con una fuente de datos de la 
cual extraer la información a desarrollar. Por tanto, y aunque fuera posible la adaptabilidad, existe una dependencia de la fuente de información. A su vez, el tener un dominio bien definido  
permite agregar bases de conocimiento previo del mismo que enriquezcan los modelos. Predominan los sistemas basados en plantillas y reglas, variando entre sí su nivel de complejidad. Estos 
sistemas son especialmente adaptables y prácticos para idiomas distintos del inglés debido a que las herramientas de generación específicas desarrolladas son menores en comparación \brackcite{gunasiri2021automated}. 
    %En el presente trabajo se presenta un prototipo de sistema basado en la propuesta de un esquema general que permita definir esquemas específicos de entradas en formas de 4-tuplas (tuplas de cuatro elementos) de %
%conocimiento de un deporte de enfrentamiento dos a dos ( beisbol, voleibol, judo, etc). A su vez, se seleccionan dos deportes, en este caso, fútbol y boxeo, y a partir de las especificaciones planteadas se %
%definen dos modelos capaces de generar un resumen informativo del evento en cuestión. Los modelos siguen el estandar basado en reglas plantillas simples de expresiones y oraciones.%

